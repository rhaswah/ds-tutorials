{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e50922-441e-4c8e-9c96-f8fca69e0ef1",
   "metadata": {},
   "source": [
    "# Modern Topic Modeling: BERTopic\n",
    "- Handles all text preprocessing: stop words, capitalization, etc..\n",
    "- Transforms each document into its own embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470a21a3-932e-4080-b38d-3d6516746fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# print(sys.executable)\n",
    "# !pip install bertopic #install in terminal\n",
    "from bertopic import BERTopic \n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a58f3a1-713a-41b0-b34a-a31f5cb14adc",
   "metadata": {},
   "source": [
    "## Data Read In\n",
    "fetch_20newsgroups is a large corpus of news articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febd1ff1-4817-4884-bb9b-088627ef97e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups()\n",
    "input_categories = [\n",
    "    'sci.space',\n",
    "    'comp.os.ms-windows.misc',\n",
    "    'comp.sys.ibm.pc.hardware',\n",
    "    'comp.sys.mac.hardware',  \n",
    "    'rec.autos',\n",
    "    'rec.motorcycles',\n",
    "    'rec.sport.baseball',\n",
    "    'rec.sport.hockey',\n",
    "    'sci.med']\n",
    "docs = fetch_20newsgroups(subset='all', categories=input_categories,remove=('headers','footers', 'quotes'))['data']  \n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d899d82-47c3-4884-ba46-2824f284f456",
   "metadata": {},
   "source": [
    "## Model Application:\n",
    "Embedding transformation and topic assignment by clustering\n",
    "\n",
    "Topic -1 contains stopwords that would traditionally be filtered out in pre-processing, such as when using LDA topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1537c925-ab2b-44c4-bc21-0e7ea400ff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a few minutes to run \n",
    "# (embedding transformation, dimensionality reduction, clustering, tf-idf representations in one line of code)\n",
    "# Remobing stop-words for interpritability\n",
    "vectorizer_model = CountVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    token_pattern=r\"(?u)\\b[a-zA-Z][a-zA-Z]{2,}\\b\"  )\n",
    "# Applying transformer topic model\n",
    "# topic_model = BERTopic(nr_topics=50, top_n_words=30,vectorizer_model=vectorizer_model)\n",
    "# topics, probs = topic_model.fit_transform(docs)\n",
    "# topic_model.save(\"bert_model\")\n",
    "topic_model = BERTopic.load(\"bert_model\")\n",
    "topic_df = topic_model.get_topic_info()\n",
    "topic_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8513eb1-16f3-4926-9ba7-2822904a38ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"topic 8:\")\n",
    "print(topic_model.get_topic(8))\n",
    "print(\"\")\n",
    "print(\"topic 9:\")\n",
    "print(topic_model.get_topic(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396a971f-3476-4565-bb0d-0d133935a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64743028-6c61-426a-8f46-82653f42ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8966c317-0c5f-4d64-83d5-e95c11c45bc0",
   "metadata": {},
   "source": [
    "## Improvements: Metric-Driven Model Evaluation, Hyperparameter Tuning, Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f5b6e5-2a3f-4c11-bf1a-d598d1ec725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.utils import simple_preprocess\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list, optimal_leaf_ordering\n",
    "from scipy.spatial.distance import squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b7bbe7-fbe5-45f2-b1d9-f5a7a390a0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = 10\n",
    "topics_dict = topic_model.get_topics()\n",
    "topic_words = [\n",
    "    [word for word, _ in words[:topk]]\n",
    "    for topic_id, words in topics_dict.items()\n",
    "    if topic_id != -1]\n",
    "topic_words[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917d9dcc-3b93-4b4d-a91d-530a6f02d3da",
   "metadata": {},
   "source": [
    "## Coherence Metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55831431-071a-40ff-bdcd-4e7c743462d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [simple_preprocess(doc) for doc in docs]\n",
    "dictionary = Dictionary(texts)\n",
    "coherence_cv = CoherenceModel(\n",
    "    topics=topic_words,\n",
    "    texts=texts,\n",
    "    dictionary=dictionary,\n",
    "    coherence=\"c_v\"\n",
    ").get_coherence()\n",
    "coherence_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f825870-b475-49ab-8639-a48228767fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_npmi = CoherenceModel(\n",
    "    topics=topic_words,\n",
    "    texts=texts,\n",
    "    dictionary=dictionary,\n",
    "    coherence=\"c_npmi\"\n",
    ").get_coherence()\n",
    "coherence_npmi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8638ac43-fa96-4f67-a31b-6c5c61a879c7",
   "metadata": {},
   "source": [
    "## Inter-topic Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae06913-1925-41fc-8897-9d265302fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_embeddings = topic_model.topic_embeddings_\n",
    "distance_matrix = cosine_distances(topic_embeddings)\n",
    "condensed_dist = squareform(distance_matrix)\n",
    "mean_intertopic_distance = np.mean(\n",
    "    distance_matrix[np.triu_indices_from(distance_matrix, k=1)])\n",
    "print(\"mean_intertopic_distance:\", mean_intertopic_distance)\n",
    "\n",
    "Z = linkage(condensed_dist, method=\"average\")\n",
    "Z = optimal_leaf_ordering(Z, condensed_dist)\n",
    "\n",
    "order = leaves_list(Z)\n",
    "distance_matrix_ordered = distance_matrix[np.ix_(order, order)]\n",
    "sns.heatmap(\n",
    "    distance_matrix_ordered,\n",
    "    cmap=\"viridis\",\n",
    "    vmin=0,\n",
    "    vmax=np.percentile(distance_matrix, 90)  # preserves diagonal contrast\n",
    ")\n",
    "plt.title(\"Inter-Topic Cosine Distance (Clustered & Ordered)\")\n",
    "plt.tight_layout()\n",
    "plt.figure(figsize=(6, 5))\n",
    "\n",
    "plt.show()\n",
    "mean_intertopic_distance = np.mean(\n",
    "    distance_matrix[np.triu_indices_from(distance_matrix, k=1)]\n",
    ")\n",
    "mean_intertopic_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba3d22d-d04b-45e0-8249-6a3c83ce9110",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"coherence_cv\": coherence_cv,\n",
    " \"coherence_npmi\": coherence_npmi,\n",
    " \"mean_intertopic_distance\": mean_intertopic_distance,\n",
    " \"num_topics\": len(topic_words)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf17c229-0a0b-406d-beb1-d8d2776ba9d8",
   "metadata": {},
   "source": [
    "## Optimal Number of Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670fb8de-1095-47d5-831f-385d3f85e607",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [simple_preprocess(doc) for doc in docs]\n",
    "dictionary = Dictionary(texts)\n",
    "\n",
    "topk = 10\n",
    "coherence_scores = {}\n",
    "\n",
    "for n in [5, 10, 20, 50]:\n",
    "    print(\"nr_topics =\", n)\n",
    "\n",
    "    model_n = BERTopic(nr_topics=n, verbose=False)\n",
    "    topics_n, _ = model_n.fit_transform(docs)\n",
    "\n",
    "    topics_dict = model_n.get_topics()\n",
    "    topic_words_n = [\n",
    "        [word for word, _ in words[:topk]]\n",
    "        for topic_id, words in topics_dict.items()\n",
    "    ]\n",
    "\n",
    "    print(\"actual_topics =\", len(topic_words_n))\n",
    "\n",
    "    coherence = CoherenceModel(\n",
    "        topics=topic_words_n,\n",
    "        texts=texts,\n",
    "        dictionary=dictionary,\n",
    "        coherence=\"c_v\"\n",
    "    ).get_coherence()\n",
    "\n",
    "    coherence_scores[n] = coherence\n",
    "coherence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142f9fd3-5eb2-41fa-90d5-10f0ca942d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by number of topics\n",
    "n_topics = sorted(coherence_scores.keys())\n",
    "scores = [coherence_scores[n] for n in n_topics]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(n_topics, scores, marker=\"o\")\n",
    "plt.xlabel(\"Number of Topics (nr_topics)\")\n",
    "plt.ylabel(\"Coherence (C_v)\")\n",
    "plt.title(\"Topic Coherence vs Topic Granularity (BERTopic)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5051a661-85c6-4137-a4a4-83e557868b25",
   "metadata": {},
   "source": [
    "## Pre-Processing: Stop-words, Alphabetical Characters, Repetition Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9055168-9f4d-4c97-94f5-db0e035e3a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repeated_patterns(text):\n",
    "    # remove any character repeated 4+ times in a row\n",
    "    text = re.sub(r'(.)\\1{3,}', '', text)\n",
    "    # remove alternating repetition like axaxaxaxax\n",
    "    text = re.sub(r'(\\b\\w{1,3})(\\1){3,}', '', text)\n",
    "    return text\n",
    "docs_clean = [remove_repeated_patterns(doc) for doc in docs]\n",
    "vectorizer_model = CountVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    token_pattern=r\"(?u)\\b[a-zA-Z][a-zA-Z]{2,}\\b\"  # only real words, min length 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
